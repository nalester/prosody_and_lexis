---
title: "The syntactic pasts of nouns shape their prosodic future: Lexico-syntactic effects on position and duration"
author: "Nicholas A. Lester"
output:
  github_document:
    toc: True
    pandoc_args: --webtex
  pandoc_args: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, cache = T, cache.lazy = F, warning = F, message = F, error = F)
```

# Summary
  
The following code was used to generate the models reported in the manuscript. There are three model types:

- model evaluating length as a function of prosodic position  
  
- models testing the relative pair-wise preference of words to specific prosodic position  
  
- model predicting the duration of a word in each of the three prosodic positions as a function of the pertinent variables
  
## 0. Preliminaries
**0.1 Clear memory (un-comment to use)**
```{r clear_mem}
# rm(list=ls(all=T))
```
  
**0.2 Install/load necessary libraries**
```{r load_libs}
list.of.packages =  c("lmerTest", 
                      "ggplot2", 
                      "visreg", 
                      "mgcv", 
                      "voxel", 
                      "effects", 
                      "languageR", 
                      "fastICA",
                      "dplyr")
new.packages = list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)){
    install.packages(new.packages)
}

invisible(lapply(list.of.packages, library, character.only = TRUE))
```
  
**0.3 Load data**
```{r load_data}
mod_dat = read.table("../Data/data_for_pub.txt", header=T, sep="\t", comment.char="", quote="")

mod_dat = mod_dat %>% filter(Det %in% c("a", "an", "the"))
```

## 1. Descriptive stats
This section produces graphs of the type/token counts per position in our sample. 
  
**1.1 Type counts per position**
```{r type_ct_per_position}
a = length(unique(mod_dat$Noun[mod_dat$facPos=="initial"]))
b = length(unique(mod_dat$Noun[mod_dat$facPos=="final"]))
c = length(unique(mod_dat$Noun[mod_dat$facPos=="medial"]))
# Note that the numbers differ because the AllThreePos condition was
# decided based on lemmas

types = data.frame(value = c(a, c, b), type = c("initial", "medial", "final"), o = c(1, 2, 3))

type.ct.plot = ggplot(data = types, aes(x=reorder(type, o), y=value, label=value)) +
  geom_bar(stat="identity", fill = "steelblue", color="black") +
  ylab("Count") +
  xlab("Position") + 
  ggtitle("Type Counts (Lemmas)") +
  theme_bw() +
  geom_text(vjust=-1) +
  ylim(0, 250) +
  theme(plot.title = element_text(hjust = 0.5), text=element_text(size=20, family = "Times New Roman"))

type.ct.plot

ggsave(type.ct.plot, file="../Results/type_count_plot.png", units = "in", width = 5, height = 3.5)
```
  
**1.2 Token counts per position**
```{r token_ct_per_position}
d = length(mod_dat$Noun[mod_dat$facPos=="initial"])
e = length(mod_dat$Noun[mod_dat$facPos=="final"])
f = length(mod_dat$Noun[mod_dat$facPos=="medial"])

tokens = data.frame(value = c(d, f, e), type = c("initial", "medial", "final"), o = c(1, 2, 3))

token.ct.plot = ggplot(data = tokens, aes(x=reorder(type, o), y=value, label=value)) +
  geom_bar(stat="identity", fill = "steelblue", color = "black") +
  ylab("Count") +
  xlab("Position") + 
  ggtitle("Token Counts") +
  theme_bw() +
  geom_text(vjust=-1) +
  ylim(0, 2700) +
  theme(plot.title = element_text(hjust = 0.5), text=element_text(size=20, family = "Times New Roman"))

token.ct.plot

ggsave(token.ct.plot, file="../Results/token_count_plot.png", units = "in", width = 5, height = 3.5)
```
  

## 2. Modeling difference in length between prosodic positions
Here we predict the duration of nouns in each of the prosodic positions (initial, medial, or final; with the caveat that the nouns are produced in DET + N constructions).  
  
Outliers were defined as nouns that took longer than 750 ms to produce. 
```{r modeling_length_between_positions}
# Descriptive
tapply(mod_dat$target.duration.ms, mod_dat$facPos, function(x) return(list(mean(x), sd(x))))

# How many outliers?
out.ct = mod_dat %>% filter(target.duration.ms>=750) %>%
         nrow()

out.prop = (out.ct/nrow(mod_dat)*100)

# Relevel predictors
len.dat = mod_dat[mod_dat$target.duration.ms<750,]
len.dat$facPos = factor(len.dat$facPos, levels = c("initial", "medial", "final"))

length.by.position = bam(target.duration.ms ~ facPos + NPhon_c + s(unsDENS_c) + s(unsLCPOSPAV_c) + s(IU_len_ms_c) + s(IU.speech.rate.graph.per.sec_c) + s(unsBPAV_c) + s(Speaker, bs="re") + s(Lemma, bs="re"), data = len.dat) 
```
  
**2.1 Results**
```{r length_between_positions_results}
anova(length.by.position)
len.mod.sum = summary(length.by.position); len.mod.sum

write.table(len.mod.sum$p.table, file="../Results/len.btw.pos_results.txt", sep="\t", quote=F)

write.table(len.mod.sum$s.table, file="../Results/len.btw.pos_results.txt", sep="\t", quote=F, append=T)
```
  
**2.2 Plotting**
```{r length_between_positions_plot}
coeff = summary(length.by.position)$p.coeff[1:3]
coeff[2] = coeff[1]+coeff[2]
coeff[3] = coeff[1]+coeff[3]

ses = summary(length.by.position)$se[1:3]

int_eff = data.frame(fit = coeff, se = ses, type = c("initial", "medial", "final"))

int_eff$type = factor(int_eff$type,levels(int_eff$type)[c(1, 3, 2)])

len.by.pos.plot = ggplot(int_eff, aes(type, fit)) +
  geom_point(color = "darkblue", size = 3) + 
  geom_errorbar(aes(ymin=fit-se, ymax=fit+se), 
                width=.4, size = 2, color="darkblue") + 
  theme_bw(base_size=24) +
  labs(color = "Position in IU", title= element_blank()) +
  ylab("Word duration (ms)") +
  theme(plot.title = element_text(hjust = 0.5), legend.position="top", legend.title = element_blank(), axis.title.y=element_blank(), legend.spacing.x = unit(0.5, 'cm'), text = element_text(family="Times New Roman")) +
  coord_flip()

len.by.pos.plot

ggsave(len.by.pos.plot, file="../Results/len_by_pos_plot.png", units = "in", width = 4, height = 3.5)
```
  
## 3. Modeling difference in positioinal preferences of words
Here we test whether the syntactic information carried by words influences where they appear in prosodic phrases.
  
**3.1 Medial vs. final**
```{r medial_vs_final_glm}
medial.vs.final = bam(facPos ~ Det + Animacy.simplified + s(lexICA1) + s(lexICA2) + s(lexICA3) + s(lexICA4) + s(lexICA5) + s(lexICA6) + s(lexICA7) + s(lexICA8) + s(lexICA9) + s(BigSurp_c) + s(Speaker,  bs="re") + s(Lemma, bs="re"), data = mod_dat[mod_dat$facPos!="initial",], family="binomial")
```
  
*3.1.1 Results*
```{r medial_vs_final_glm_results}
m.v.f.results = summary(medial.vs.final); m.v.f.results
anova(medial.vs.final)

write.table(m.v.f.results$p.table, file="../Results/m.v.f_results.txt", sep="\t", quote=F)

write.table(m.v.f.results$s.table, file="../Results/m.v.f_results.txt", sep="\t", quote=F, append=T)
```
  
*3.1.2 Plotting*
```{r medial_vs_final_glm_plot}
# Construct hypothetical dataset (non-target variables held at median or alphabetically prior level)
orig_data = mod_dat[mod_dat$facPos!="initial",]
new_data = with(orig_data, 
                expand.grid(lexICA4 = seq(min(lexICA4), 
                                              max(lexICA4), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA2 = median(lexICA2),
                            lexICA3 = median(lexICA3),
                            lexICA5 = median(lexICA5),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate"))

# Define the link function for back-transforming
ilink = family(medial.vs.final)$linkinv

# Generate predicted values in log-odds (without random effects)
pred = predict(medial.vs.final, 
               new_data, 
               type = "link", 
               se.fit = TRUE, 
               exclude = c("s(Speaker)", "s(Lemma)", "Animacy.simplified", "Det"))

# Add the predicted values to our hypothetical dataframe
pred = cbind(pred, new_data)

# Back-transform fitted values and CIs into the response scale (i.e., probabilities rather than log-odds)
pred = transform(pred, lwr_ci = ilink(fit - (2 * se.fit)),
                       upr_ci = ilink(fit + (2 * se.fit)),
                       fitted = ilink(fit))

# Plot the result
m.v.f = ggplot(pred, aes(x = lexICA4, y = fitted)) +
        geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                    fill = "dodgerblue",
                    color = "dodgerblue",
                    alpha = 0.2) +
        geom_line() +
        geom_hline(yintercept=.5, lty=2, color="grey50") +
        ylim(0,1) +
        annotate("text", 
                 x = -2, 
                 y = .85, 
                 label = "medial", 
                 family = "Times New Roman", 
                 hjust=0) +
        annotate("text", 
                 x=-2, 
                 y=.15, 
                 label = "final", 
                 family="Times New Roman", 
                 hjust=0) +
        xlab("Component 4 (syntactic diversity →)") +
        ylab("Probability") +
        theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"))

m.v.f

ggsave(m.v.f, file = "../Results/medial_vs_final_plot.png", units="in", width = 5, height = 3.5, device = "png")
```

**3.2 Initial vs. medial**
```{r initial_vs_medial_glm}
initial.vs.medial = bam(facPos ~ Det + Animacy.simplified + s(lexICA1) + s(lexICA2) + s(lexICA3) + s(lexICA4) + s(lexICA5) + s(lexICA6) + s(lexICA7) + s(lexICA8) + s(lexICA9) + s(BigSurp_c) + s(Speaker,  bs="re") + s(Lemma, bs="re"), data=mod_dat[mod_dat$facPos!="final",], family="binomial")
```
  
*3.2.1 Results*
```{r initial_vs_medial_glm_results}
i.v.m.results = summary(initial.vs.medial); i.v.m.results
anova(initial.vs.medial)

write.table(i.v.m.results$p.table, file="../Results/i.v.m_results.txt", sep="\t", quote=F)

write.table(i.v.m.results$s.table, file="../Results/i.v.m_results.txt", sep="\t", quote=F, append=T)
```
  
*3.2.2 Plotting*
```{r initial_vs_medial_glm_plot}
# Construct hypothetical dataset (non-target variables held at median or alphabetically prior level)
orig_data = mod_dat[mod_dat$facPos!="final",]
new_data = with(orig_data, 
                expand.grid(lexICA4 = seq(min(lexICA4), 
                                              max(lexICA4), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA2 = median(lexICA2),
                            lexICA3 = median(lexICA3),
                            lexICA5 = median(lexICA5),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate"))

# Define the link function for back-transforming
ilink = family(initial.vs.medial)$linkinv

# Generate predicted values in log-odds (without random effects)
pred = predict(initial.vs.medial, 
               new_data, 
               type = "link", 
               se.fit = TRUE, 
               exclude = c("s(Speaker)", "s(Lemma)", "Det", "Animacy.simplfied"))

# Add the predicted values to our hypothetical dataframe
pred = cbind(pred, new_data)

# Back-transform fitted values and CIs into the response scale (i.e., probabilities rather than log-odds)
pred = transform(pred, lwr_ci = ilink(fit - (2 * se.fit)),
                       upr_ci = ilink(fit + (2 * se.fit)),
                       fitted = ilink(fit))

# Plot the result
i.v.m = ggplot(pred, aes(x = lexICA4, y = fitted)) +
        geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                    fill = "dodgerblue",
                    color = "dodgerblue",
                    alpha = 0.2) +
        geom_line() +
        geom_hline(yintercept=.5, lty=2, color="grey50") +
        ylim(0,1) +
        annotate("text", 
                 x = -2, 
                 y = .75, 
                 label = "medial", 
                 family = "Times New Roman", 
                 hjust=0) +
        annotate("text", 
                 x=-2, 
                 y=.25, 
                 label = "initial", 
                 family="Times New Roman", 
                 hjust=0) +
        xlab("Component 4 (syntactic diversity →)") +
        ylab("Probability") +
        theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"))

i.v.m

ggsave(i.v.m, file = "../Results/initial_vs_medial_plot.png", units="in", width = 5, height = 3.5, device = "png")

```

**3.3 Initial vs. final**
```{r initial_vs_final_glm}
initial.vs.final = bam(facPos ~ Det + Animacy.simplified + s(lexICA1) + s(lexICA2) + s(lexICA3) + s(lexICA4) + s(lexICA5) + s(lexICA6) + s(lexICA7) + s(lexICA8) + s(lexICA9) + s(BigSurp_c) + s(Speaker,  bs="re") + s(Lemma, bs="re"), data=mod_dat[mod_dat$facPos!="medial",], family="binomial")
```
  
*3.3.1 Results*
```{r initial_vs_final_glm_results}
i.v.f.results = summary(initial.vs.final); i.v.f.results
anova(initial.vs.final)

write.table(i.v.f.results$p.table, file="../Results/i.v.f_results.txt", sep="\t", quote=F)

write.table(i.v.f.results$s.table, file="../Results/i.v.f_results.txt", sep="\t", quote=F, append=T)
```
  
*3.3.2 Plotting*
```{r initial_vs_final_glm_plot}
# Construct hypothetical dataset (non-target variables held at median or alphabetically prior level)
orig_data = mod_dat[mod_dat$facPos!="medial",]
new_data = with(orig_data, 
                expand.grid(lexICA4 = seq(min(lexICA4), 
                                              max(lexICA4), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA2 = median(lexICA2),
                            lexICA3 = median(lexICA3),
                            lexICA5 = median(lexICA5),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate"))

# Define the link function for back-transforming
ilink = family(initial.vs.final)$linkinv

# Generate predicted values in log-odds (without random effects)
pred = predict(initial.vs.final, 
               new_data, 
               type = "link", 
               se.fit = TRUE, 
               exclude = c("s(Speaker)", "s(Lemma)", "Det", "Animacy.simplified"))

# Add the predicted values to our hypothetical dataframe
pred = cbind(pred, new_data)

# Back-transform fitted values and CIs into the response scale (i.e., probabilities rather than log-odds)
pred = transform(pred, lwr_ci = ilink(fit - (2 * se.fit)),
                       upr_ci = ilink(fit + (2 * se.fit)),
                       fitted = ilink(fit))

# Plot the result
i.v.f = ggplot(pred, aes(x = lexICA4, y = fitted)) +
        geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                    fill = "dodgerblue",
                    color = "dodgerblue",
                    alpha = 0.2) +
        geom_line() +
        geom_hline(yintercept=.5, lty=2, color="grey50") +
        ylim(0,1) +
        annotate("text", 
                 x = -2, 
                 y = .75, 
                 label = "initial", 
                 family = "Times New Roman", 
                 hjust=0) +
        annotate("text", 
                 x=-2, 
                 y=.25, 
                 label = "final", 
                 family="Times New Roman", 
                 hjust=0) +
        xlab("Component 4 (syntactic diversity →)") +
        ylab("Probability") +
        theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"))

i.v.f

ggsave(i.v.f, file = "../Results/initial_vs_final_plot.png", units="in", width = 5, height = 3.5, device = "png")

```

**3.4 Correct p-values for multiple comparisons (Benjamini-Yekutieli method)**
Because we are performing multiple tests on the same data, we correct the p-values from all models.
  
*3.4.1 Get p-values from each model*
```{r get_ps}
## Medial vs. final
test1 = summary(medial.vs.final)

## Initial vs. medial
test2 = summary(initial.vs.medial)

## Initial vs. final
test3 = summary(initial.vs.final)
```
  
*3.4.2 Concatenate all p's*
```{r concatenate_ps}
pvals = c(test1$p.pv, test1$s.pv[1:10], test2$p.pv, test2$s.pv[1:10], test3$p.pv, test3$s.pv[1:10])
```
  
*3.4.3 Adjust p-values with B-Y (false-discovery rate) correction and add to data*
```{r adjust_ps}
adjustedPs = p.adjust(pvals, method="BY")

## 3.4.6 Put adjusted p's into a human-readable table
model.label.1 = rep("medial_vs_final", 14)
model.label.2 = rep("initial_vs_medial", 14)
model.label.3 = rep("initial_vs_final", 14)

model.labels = c(model.label.1, model.label.2, model.label.3)

p.df = data.frame(Model = model.labels, Variable = rep(c("Intercept", "Determiner: an", "Determiner: the", "Animacy: inanimate", "Component 1", "Component 2", "Component 3", "Component 4", "Component 5", "Component 6", "Component 7", "Component 8", "Component 9", "Bigram surprisal"), 3), p.values = round(pvals, 3), corrected.p.values = round(adjustedPs, 3))

p.df

write.table(p.df, file = "../Results/glmer_adjusted_pvalues.txt", sep = "\t", row.names = F, quote = F)

# Adjusting only p-values for the critical predictors
crit.pvals = c(test1$s.pv[c(2,4:5)], test2$s.pv[c(2,4:5)], test3$s.pv[c(2,4:5)])

crit.adjustedPs = p.adjust(crit.pvals, method="BY")
crit.mod.labels = c(rep(c("medial_vs_final", "initial_vs_medial", "initial_vs_final"), each=3)) 

crit.p.df = data.frame(Model = crit.mod.labels, Variable = rep(c("Component 2", "Component 4", "Component 5"), each = 3), p.values = round(crit.pvals, 3), corrected.p.values = round(crit.adjustedPs, 3))

crit.p.df

write.table(crit.p.df, file = "../Results/glmer_adjusted_pvalues_critical_vars_only.txt", sep = "\t", row.names = F, quote = F)
```
  
## 4. Modeling differences in duration within positions
Finally, we look inside each prosodic position to see if the lexico-syntactic variables play a role in determining duration.
  
Overly long nouns (> 750 ms) were removed prior to the analysis.
```{r modeling_duration_in_position}
duration.in.position = bam(target.duration.ms ~ Det + Animacy.simplified + s(lexICA1, by=facPos) + s(lexICA2, by=facPos) + s(lexICA3, by=facPos) + s(lexICA4, by=facPos) + s(lexICA5, by=facPos) + s(lexICA6, by=facPos) + s(lexICA7, by=facPos) + s(lexICA8, by=facPos) + s(lexICA9, by=facPos) + s(IU.speech.rate.graph.per.sec_c, by=facPos) + s(IU_len_ms_c, by=facPos) + s(BigSurp_c, by=facPos) + s(Lemma, bs="re") + s(Speaker, bs="re"), data=mod_dat[mod_dat$target.duration.ms<750,])

# With syllable-based IU speech rate measure
duration.in.position.wSyll = bam(target.duration.ms ~ Det + Animacy.simplified + s(lexICA1, by=facPos) + s(lexICA2, by=facPos) + s(lexICA3, by=facPos) + s(lexICA4, by=facPos) + s(lexICA5, by=facPos) + s(lexICA6, by=facPos) + s(lexICA7, by=facPos) + s(lexICA8, by=facPos) + s(lexICA9, by=facPos) + s(IU.speech.rate.syll.per.sec_c, by=facPos) + s(IU_len_ms_c, by=facPos) + s(BigSurp_c, by=facPos) + s(Lemma, bs="re") + s(Speaker, bs="re"), data=mod_dat[mod_dat$target.duration.ms<750,])
```
  
**4.1 Results**
```{r duration_in_position_results}
duration.results = summary(duration.in.position); duration.results
anova(duration.in.position)

write.table(duration.results$p.table, file="../Results/duration_in_position_results.txt", sep="\t", quote=F)

write.table(duration.results$s.table, file="../Results/duration_in_position_results.txt", sep="\t", quote=F, append=T)

# With syllable-based IU speech rate measure
anova(duration.in.position.wSyll)
```
  
**4.2 Plotting**  
*4.2.1 Component 5, initial position*
```{r duration_in_pos_initial_plot}
# Construct hypothetical dataset (non-target variables held at median or alphabetically prior level)
orig_data = mod_dat
new_data = with(orig_data, 
                expand.grid(lexICA5 = seq(min(lexICA5), 
                                              max(lexICA5), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA2 = median(lexICA2),
                            lexICA3 = median(lexICA3),
                            lexICA4 = median(lexICA4),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            IU.speech.rate.graph.per.sec_c = median(IU.speech.rate.graph.per.sec_c),
                            IU_len_ms_c = median(IU_len_ms_c),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate",
                            facPos = "initial"))

# Generate predicted values in log-odds (without random effects)
pred = predict(duration.in.position, 
               new_data, 
               type = "response", 
               se.fit = TRUE, 
               exclude = c("s(Speaker)", "s(Lemma)", "Det", "Animacy.simplified"))

# Add the predicted values to our hypothetical dataframe
pred = cbind(pred, new_data)

# Add CI
pred$lwr_ci = pred$fit - (2 * pred$se.fit)
pred$upr_ci = pred$fit + (2 * pred$se.fit)

# Plot the result
d.init = ggplot(pred, aes(x = lexICA5, y = fit)) +
         geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                     fill = "dodgerblue",
                     color = "dodgerblue",
                     alpha = 0.2) +
         geom_line() +
         xlab("Component 5 (syntactic typicality →)") +
         ylab("Duration (ms)") +
         ggtitle("Initial") +
         theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"),
               plot.title = element_text(hjust=0.5))

d.init

ggsave(d.init, file = "../Results/comp5_initial_plot.png", units="in", width = 5, height = 3.5, device = "png")
```
  
*4.2.2 Component 5, medial position*
```{r duration_in_pos_medial_plot}
new_data = with(orig_data, 
                expand.grid(lexICA5 = seq(min(lexICA5), 
                                              max(lexICA5), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA2 = median(lexICA2),
                            lexICA3 = median(lexICA3),
                            lexICA4 = median(lexICA4),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            IU.speech.rate.graph.per.sec_c = median(IU.speech.rate.graph.per.sec_c),
                            IU_len_ms_c = median(IU_len_ms_c),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate",
                            facPos = "medial"))

# Generate predicted values in log-odds (without random effects)
pred = predict(duration.in.position, 
               new_data, 
               type = "response", 
               se.fit = TRUE, 
               exclude = c("s(Speaker)", "s(Lemma)", "Det", "Animacy.simplified"))

# Add the predicted values to our hypothetical dataframe
pred = cbind(pred, new_data)

# Add CI
pred$lwr_ci = pred$fit - (2 * pred$se.fit)
pred$upr_ci = pred$fit + (2 * pred$se.fit)

# Plot the result
d.medi = ggplot(pred, aes(x = lexICA5, y = fit)) +
         geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                     fill = "dodgerblue",
                     color = "dodgerblue",
                     alpha = 0.2) +
         geom_line() +
         xlab("Component 5 (syntactic typicality →)") +
         ylab("Duration (ms)") +
         ggtitle("Medial") +
         theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"),
               plot.title = element_text(hjust=0.5))

d.medi

ggsave(d.medi, file = "../Results/comp5_medial_plot.png", units="in", width = 5, height = 3.5, device = "png")
```
  
*4.2.3 Component 5, final position*
```{r duration_in_pos_final_plot}
new_data = with(orig_data, 
                expand.grid(lexICA5 = seq(min(lexICA5), 
                                              max(lexICA5), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA2 = median(lexICA2),
                            lexICA3 = median(lexICA3),
                            lexICA4 = median(lexICA4),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            IU.speech.rate.graph.per.sec_c = median(IU.speech.rate.graph.per.sec_c),
                            IU_len_ms_c = median(IU_len_ms_c),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate",
                            facPos = "final"))

# Generate predicted values in log-odds (without random effects)
pred.5.final = predict(duration.in.position, 
               new_data, 
               type = "response", 
               se.fit = TRUE, 
               exclude = c("s(Speaker)", "s(Lemma)", "Det", "Animacy.simplified"))

# Add the predicted values to our hypothetical dataframe
pred.5.final = cbind(pred.5.final, new_data)

# Add CI
pred.5.final$lwr_ci = pred.5.final$fit - (2 * pred.5.final$se.fit)
pred.5.final$upr_ci = pred.5.final$fit + (2 * pred.5.final$se.fit)

# Plot the result
d.fina = ggplot(pred.5.final, aes(x = lexICA5, y = fit)) +
         geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                     fill = "dodgerblue",
                     color = "dodgerblue",
                     alpha = 0.2) +
         geom_line() +
         xlab("Component 5 (syntactic typicality →)") +
         ylab("Duration (ms)") +
         ggtitle("Final") +
         theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"),
               plot.title = element_text(hjust=0.5))


d.fina
```
  
*4.2.4 Component 2, initial position*
```{r component_2_initial_plot}
new_data = with(orig_data, 
                expand.grid(lexICA2 = seq(min(lexICA2), 
                                              max(lexICA2), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA5 = median(lexICA5),
                            lexICA3 = median(lexICA3),
                            lexICA4 = median(lexICA4),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            IU.speech.rate.graph.per.sec_c = median(IU.speech.rate.graph.per.sec_c),
                            IU_len_ms_c = median(IU_len_ms_c),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate",
                            facPos = "initial"))

# Generate predicted values in log-odds (without random effects)
pred = predict(duration.in.position, 
               new_data, 
               type = "response", 
               se.fit = TRUE, 
               exclude = c("s(Speaker)", "s(Lemma)", "Det", "Animacy.simplified"))

# Add the predicted values to our hypothetical dataframe
pred = cbind(pred, new_data)

# Add CI
pred$lwr_ci = pred$fit - (2 * pred$se.fit)
pred$upr_ci = pred$fit + (2 * pred$se.fit)

# Plot the result
d.init.comp2 = ggplot(pred, aes(x = -lexICA2, y = fit)) +
         geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                     fill = "dodgerblue",
                     color = "dodgerblue",
                     alpha = 0.2) +
         geom_line() +
         xlab("Component 2 (syntactic diversity + frequency →)") +
         ylab("Duration (ms)") +
         ggtitle("Initial") +
         theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"),
               plot.title = element_text(hjust=0.5)) 

d.init.comp2
```
  
*4.2.5 Component 2, medial position*
```{r component_2_medial_plot}
new_data = with(orig_data, 
                expand.grid(lexICA2 = seq(min(lexICA2), 
                                              max(lexICA2), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA5 = median(lexICA5),
                            lexICA3 = median(lexICA3),
                            lexICA4 = median(lexICA4),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            IU.speech.rate.graph.per.sec_c = median(IU.speech.rate.graph.per.sec_c),
                            IU_len_ms_c = median(IU_len_ms_c),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate",
                            facPos = "medial"))

# Generate predicted values in log-odds (without random effects)
pred = predict(duration.in.position, 
               new_data, 
               type = "response", 
               se.fit = TRUE, 
               exclude = c("s(Speaker)", "s(Lemma)", "Det", "Animacy.simplified"))

# Add the predicted values to our hypothetical dataframe
pred = cbind(pred, new_data)

# Add CI
pred$lwr_ci = pred$fit - (2 * pred$se.fit)
pred$upr_ci = pred$fit + (2 * pred$se.fit)

# Plot the result
d.medi.comp2 = ggplot(pred, aes(x = -lexICA2, y = fit)) +
         geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                     fill = "dodgerblue",
                     color = "dodgerblue",
                     alpha = 0.2) +
         geom_line() +
         xlab("Component 2 (syntactic diversity + frequency →)") +
         ylab("Duration (ms)") +
         ggtitle("Medial") +
         theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"),
               plot.title = element_text(hjust=0.5)) 

d.medi.comp2

ggsave(d.medi.comp2, file = "../Results/comp2_medial_plot.png", units="in", width = 5, height = 3.5, device = "png")
```
  
*4.2.6 Component 2, final position*
```{r component_2_final_plot}
new_data = with(orig_data, 
                expand.grid(lexICA2 = seq(min(lexICA2), 
                                              max(lexICA2), 
                                              length = 10),
                            lexICA1 = median(lexICA1),
                            lexICA5 = median(lexICA5),
                            lexICA3 = median(lexICA3),
                            lexICA4 = median(lexICA4),
                            lexICA6 = median(lexICA6),
                            lexICA7 = median(lexICA7),
                            lexICA8 = median(lexICA8),
                            lexICA9 = median(lexICA9),
                            IU.speech.rate.graph.per.sec_c = median(IU.speech.rate.graph.per.sec_c),
                            IU_len_ms_c = median(IU_len_ms_c),
                            BigSurp_c = median(BigSurp_c),
                            Det = "a",
                            Speaker = "AL",
                            Lemma = "air",
                            Animacy.simplified = "inanimate",
                            facPos = "final"))

# Generate predicted values in log-odds (without random effects)
pred.2.final = predict(duration.in.position, 
                       new_data, 
                       type = "response", 
                       se.fit = TRUE, 
                       exclude = c("s(Speaker)", "s(Lemma)", "Det", "Animacy.simplified"))

# Add the predicted values to our hypothetical dataframe
pred.2.final = cbind(pred.2.final, new_data)

# Add CI
pred.2.final$lwr_ci = pred.2.final$fit - (2 * pred.2.final$se.fit)
pred.2.final$upr_ci = pred.2.final$fit + (2 * pred.2.final$se.fit)

# Plot the result
d.fina.comp2 = ggplot(pred.2.final, aes(x = -lexICA2, y = fit)) +
         geom_ribbon(aes(ymin = lwr_ci, ymax = upr_ci), 
                     fill = "dodgerblue",
                     color = "dodgerblue",
                     alpha = 0.2) +
         geom_line() +
         xlab("Component 2 (syntactic diversity + frequency →)") +
         ylab("Duration (ms)") +
         ggtitle("Final") +
         theme_bw() +
         theme(text = element_text(family="Times New Roman",
                                   size=14,
                                   face="bold"),
               plot.title = element_text(hjust=0.5)) 

d.fina.comp2
```
  
**NB**: To aid interpretation, we reverse the sign of the Component 2 values. The arrow in the x-axis label indicates how the variables increase relative to the component scores. 
